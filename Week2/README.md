# Week 2: Linear and Logistic Regression

## Regression

Before we begin developing full-fledged neural networks, we begin by understanding one of the most fundamental machine learning techniques- regression.

In this week, you will understand the logic behind linear and logistic regression, and how we harness mathematical and computational power to solve problems.

The resources for this week will be the [**online course on Supervised Learning**](https://www.coursera.org/learn/machine-learning) on Coursera by Andrew NG. It is highly recommended that you complete all the video tutorials by the end of this week.

You do not need to enrol for the course, you can audit all the content for free.

<img src="../misc/coursera_audit.png" width="70%" height="70%"></img>  
*Upon pressing the Enroll for Free button, you will see this popup. Click on the "Audit" hyperlink near the bottom, below the continue button*

Learning to implement logistic regression from scratch fosters a deeper understanding of the algorithm's mechanics, parameter optimization using gradient descent and model evaluation.
Run a gradient descent model to predict the chance of having Coronary Heart Disease in 10 years on this [**dataset**](https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression).

## Neural Networks

Although we won't formally start with neural networks until next week, [**here**](https://www.youtube.com/watch?v=aircAruvnKk) is a short YouTube playlist that explains neural networks very nicely, do go through it!

As an optional task for the most enthusiastic ones, you can follow this [**playlist**](https://youtu.be/Wo5dMEP_BbI?feature=shared) to implement a Neural Network from scratch in raw Python.
Note: The above task is a nice way to understand the code implementation but give it a try only after finishing this week's work. 
